{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f112197a",
   "metadata": {},
   "source": [
    "# **HANDS-ON**\n",
    "\n",
    "In order to be able to run Spark for these examples it is necessary to use pyspark. \n",
    "\n",
    "In order to install pyspark run \"pip install pyspark -v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f904d0",
   "metadata": {},
   "source": [
    "**BROADCAST HASH JOIN**\n",
    "\n",
    "In this first example it will be possible to observe how the catalyst chooses a Broadcast Hash Join strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e280b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold= 1024*1024*10\n",
    "\n",
    "spark= (SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AQEOff\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.sql.adaptive.enabled\",\"false\")\\\n",
    "    .config(\"spark.eventLog.enabled\", \"false\")\\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", threshold)\\\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5fbad",
   "metadata": {},
   "source": [
    "Let's go take a look at the UI:\n",
    "\n",
    "localhost:4040\n",
    "\n",
    "Given that no instuctions have been given to Spark, there is nothing to see yet.\n",
    "\n",
    "Let's try to perform a join between tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA=spark.read.parquet(\"./Data/bigTableA\")\n",
    "dfK=spark.read.parquet(\"./Data/keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af936f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult_=dfA.join(dfK, dfA.LAVORO_A==dfK.LAVORO_KEYS, \"left\")\n",
    "print(dfResult_.explain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult_.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult_=dfResult_.filter(dfResult_.LAVORO_A == \"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult_.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57818e3",
   "metadata": {},
   "source": [
    "**Sort Merge Join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB=spark.read.parquet(\"./Data/bigTableB\")\n",
    "dfAux=dfB\\\n",
    "    .join(dfK, dfB.LAVORO_B==dfK.LAVORO_KEYS, \"left\")\\\n",
    "    .filter(\"FILLER1==FILLER2 and FILLER2==FILLER3\")\\\n",
    "    .repartition(200)\n",
    "dfResult_ =dfA.join(dfAux, dfA.LAVORO_A==dfAux.LAVORO_B, \"left\")\n",
    "\n",
    "print(dfResult_.explain())\n",
    "dfResult_.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da131975",
   "metadata": {},
   "source": [
    "# **Dynamic Optimization**\n",
    "\n",
    "Let's take a look at how Spark dynamically switches join strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold= 1024*1024*10\n",
    "\n",
    "spark= (SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AQEOn\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.sql.adaptive.enabled\",\"true\")\\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\\\n",
    "    .config( \"spark.sql.adaptive.skewJoin.enabled\",\"false\")\\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", threshold)\\\n",
    "    .config(\"spark.eventLog.enabled\", \"false\")\\\n",
    "    .getOrCreate())\n",
    "\n",
    "dfA=spark.read.parquet(\"./Data/bigTableA\")\n",
    "dfB =spark.read.parquet(\"./Data/bigTableB\")\n",
    "dfK=spark.read.parquet(\"./Data/keys\")\n",
    "dfAux=dfB\\\n",
    "    .join(dfK, dfB.LAVORO_B==dfK.LAVORO_KEYS, \"left\")\\\n",
    "    .filter(\"FILLER1==FILLER2 and FILLER2==FILLER3\")\\\n",
    "    .repartition(200)\n",
    "dfResult_ =dfA.join(dfAux, dfA.LAVORO_A==dfAux.LAVORO_B, \"left\")\n",
    "\n",
    "print(dfResult_.explain())\n",
    "dfResult_.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164658f",
   "metadata": {},
   "source": [
    "What happens if the repartition is removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAux=dfB\\\n",
    "    .join(dfK, dfB.LAVORO_B==dfK.LAVORO_KEYS, \"left\")\\\n",
    "    .filter(\"FILLER1==FILLER2 and FILLER2==FILLER3\")\n",
    "dfResult_ =dfA.join(dfAux, dfA.LAVORO_A==dfAux.LAVORO_B, \"left\")\n",
    "\n",
    "print(dfResult_.explain())\n",
    "dfResult_.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8575fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d4ddb",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "Remember to shut down the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71499cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
